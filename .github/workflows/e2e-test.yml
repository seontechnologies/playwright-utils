name: Run e2e tests
on:
  push:
  pull_request:
    types: [opened, synchronize, reopened, labeled, unlabeled]
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  TEST_ENV: dev
  TEST_COMMAND: npm run test:pw
  INSTALL_COMMAND: npm ci

jobs:
  vars:
    runs-on: kubernetes-default
    outputs:
      test_env: ${{ env.TEST_ENV }}
      test_command: ${{ env.TEST_COMMAND }}
      install_command: ${{ env.INSTALL_COMMAND }}
      skip_burn_in: ${{ steps.check_skip_label.outputs.skip_burn_in }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Check for skip_burn_in label
        id: check_skip_label
        run: |
          # For PRs, check if the label exists
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # The contains() function will evaluate to either 'true' or 'false'
            LABEL_EXISTS="${{ contains(github.event.pull_request.labels.*.name, 'skip_burn_in') }}"
            echo "skip_burn_in=${LABEL_EXISTS}" >> $GITHUB_OUTPUT
            
            if [ "${LABEL_EXISTS}" = "true" ]; then
              echo "✅ Found skip_burn_in label. Burn-in tests will be skipped."
            else
              echo "No skip_burn_in label found. Running burn-in tests."
            fi
          else
            # For non-PR events, always run burn-in
            echo "skip_burn_in=false" >> $GITHUB_OUTPUT
            echo "Not a PR event. Running burn-in tests."
          fi

      - run: echo "Exposing env vars"

  burn-in:
    needs: vars
    if: needs.vars.outputs.skip_burn_in != 'true'
    uses: ./.github/workflows/rwf-burn-in.yml
    with:
      base-ref: 'main'
      test-directory: 'playwright/'
      test-pattern: '.*\.spec\.ts'
      repeat-count: 3 # this will run 6 times between the 2 browsers (chrome & chromium)
      retry-count: 0
      install-command: ${{ needs.vars.outputs.install_command }}
      test-command: ${{ needs.vars.outputs.test_command }}

  e2e-test:
    needs: [vars, burn-in]
    timeout-minutes: 10
    # This conditional logic ensures e2e tests run in three scenarios:
    # 1. When the skip_burn_in label is present (we skip burn-in but still run e2e tests)
    # 2. When burn-in job runs and completes successfully (normal flow with test changes)
    # 3. When burn-in job is skipped because no test files changed (only src changes)
    # The always() ensures this job evaluates even if burn-in is skipped or never ran
    if: |
      always() && 
      (needs.vars.outputs.skip_burn_in == 'true' || 
       (needs.burn-in.result == 'success' && needs.burn-in.outputs.runE2E == 'true') ||
       (needs.burn-in.result == 'skipped'))
    strategy:
      fail-fast: false
      matrix:
        shardIndex: [1, 2]
        shardTotal: [2]
    runs-on: kubernetes-default
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-${{ runner.os }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-${{ runner.os }}-

      - name: Install dependencies
        run: ${{ needs.vars.outputs.install_command }}

      # I wish this worked, but it breaks PW tests https://github.com/seontechnologies/playwright-utils/actions/runs/15164591575/job/42639824935#step:11:163
      # - name: Cache Playwright Browsers
      #   id: cache-browsers
      #   uses: actions/cache@v4
      #   with:
      #     path: ~/.cache/ms-playwright
      #     key: playwright-${{ runner.os }}-${{ hashFiles('**/package-lock.json') }}-${{ github.run_id }}
      #     restore-keys: |
      #       playwright-${{ runner.os }}-

      - name: Install Playwright Browsers
        # if: steps.cache-browsers.outputs.cache-hit != 'true' # I wish this worked
        run: |
          npx playwright install --with-deps chromium
          npx playwright install --with-deps chrome

      - name: Verify Browsers
        run: |
          npx playwright install --dry-run
          echo "Playwright browsers installed at:"
          ls -la ~/.cache/ms-playwright/

      - name: Start Kafka
        continue-on-error: true # If Kafka fails to start, tests without Kafka can still run
        run: |
          docker compose -f ./sample-app/backend/src/events/kafka-cluster.yml up -d --no-recreate

      # Add robust waiting for Kafka to be ready with health checks
      - name: Wait for Kafka to be ready
        continue-on-error: true # Tests can still run without Kafka
        run: |
          echo "Waiting for Kafka containers to initialize..."
          # First wait for containers to fully start up (30 seconds max)
          sleep 5
          for i in {1..5}; do
            echo "Attempt $i: Checking if Kafka containers are running..."
            if docker ps | grep -q "events-kafka"; then
              echo "Kafka container is running"
              break
            fi
            sleep 5
          done

          # Now wait for Kafka to be responsive (allow up to 3 failures)
          for i in {1..3}; do
            echo "Attempt $i: Checking Kafka connectivity..."
            if node ./sample-app/backend/scripts/kafka-health-check.js; then
              echo "✅ Kafka is ready!"
              break
            else
              echo "⚠️ Kafka health check failed on attempt $i, retrying..."
              # Give Kafka a bit more time to initialize
              sleep 10
            fi
          done

          echo "Proceeding with tests (Kafka may or may not be fully ready)"

      - name: Run Playwright tests
        run: ${{ needs.vars.outputs.test_command }} -- --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}
        env:
          # Set env variables to indicate we're in CI (used by Kafka health check)
          CI: 'true'
          # Ensure tests don't fail due to Kafka issues
          ALLOW_KAFKA_FAILURE: 'true'

      # Stop Kafka after tests
      - name: Stop Kafka
        continue-on-error: true
        if: always()
        run: docker compose -f ./sample-app/backend/src/events/kafka-cluster.yml down

      - name: Copy trace files to blob-report
        run: |
          mkdir -p blob-report/trace
          cp -r test-results/**/*.zip blob-report/trace || true

      - name: Upload shared blob report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: blob-report-${{ matrix.shardIndex }}
          path: blob-report
          retention-days: 3

  merge-reports:
    needs: e2e-test
    # even if the previous jobs in the needs: list failed, still run this job
    if: always() && needs.burn-in.outputs.runE2E == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Download shard reports
        uses: actions/download-artifact@v4
        with:
          path: all-blob-reports
          pattern: blob-report-*
          merge-multiple: true

      - name: Merge Playwright reports
        run: |
          mkdir -p playwright-report/trace
          cp -r all-blob-reports/*/trace/* playwright-report/trace || true
          npx playwright merge-reports --reporter=html all-blob-reports

      - name: Upload merged report
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
          retention-days: 3
