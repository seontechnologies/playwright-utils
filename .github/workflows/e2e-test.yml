name: Run e2e tests
on:
  push:
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  TEST_ENV: dev
  TEST_COMMAND: npm run test:pw
  INSTALL_COMMAND: npm ci

jobs:
  vars:
    runs-on: kubernetes-default
    outputs:
      test_env: ${{ env.TEST_ENV }}
      test_command: ${{ env.TEST_COMMAND }}
      install_command: ${{ env.INSTALL_COMMAND }}
    steps:
      - run: echo "Exposing env vars"

  burn-in:
    needs: vars
    uses: ./.github/workflows/rwf-burn-in.yml
    with:
      base-ref: 'main'
      test-directory: 'playwright/'
      test-pattern: '.*\.spec\.ts'
      repeat-count: 3 # this will run 6 times between the 2 browsers (chrome & chromium)
      retry-count: 0
      install-command: ${{ needs.vars.outputs.install_command }}
      test-command: ${{ needs.vars.outputs.test_command }}

  e2e-test:
    needs: [vars, burn-in]
    timeout-minutes: 10
    if: needs.burn-in.outputs.runE2E == 'true'
    strategy:
      fail-fast: false
      matrix:
        shardIndex: [1, 2]
        shardTotal: [2]
    runs-on: kubernetes-default
    services:
      zookeeper:
        image: confluentinc/cp-zookeeper:7.3.0
        ports: ['2181:2181']
        env:
          ZOOKEEPER_CLIENT_PORT: '2181'
          ZOOKEEPER_TICK_TIME: '2000'

      kafka:
        image: confluentinc/cp-kafka:7.3.0
        ports: ['9092:9092']
        env:
          KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
          KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: '1'
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: '0'
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: '1'
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: '1'
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'

      - name: Cache Playwright Browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          # only creates a new cache when dependencies change
          key: playwright-${{ runner.os }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-${{ runner.os }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-${{ runner.os }}-

      - name: Install dependencies
        run: ${{ needs.vars.outputs.install_command }}

      - name: Install Playwright Chromium
        run: |
          npx playwright install --with-deps chromium
          npx playwright install --with-deps chrome

      # Kafka is now managed by GitHub Actions service containers
      - name: Wait for Kafka to be ready
        continue-on-error: true # Tests can still run without Kafka
        run: |
          echo "Waiting for Kafka to be ready..."
          for i in {1..10}; do
            if kcat -L -b localhost:9092; then
              echo "✅ Kafka is ready!"
              exit 0
            fi
            echo "⚠️ Waiting for Kafka to be ready (attempt $i/10)..."
            sleep 3
          done
          echo "⚠️ Kafka not ready, proceeding with tests anyway..."

      - name: Run Playwright tests
        run: ${{ needs.vars.outputs.test_command }} -- --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}
        env:
          # Set env variables to indicate we're in CI (used by Kafka health check)
          CI: 'true'
          # Ensure tests don't fail due to Kafka issues
          ALLOW_KAFKA_FAILURE: 'true'

      # Stop Kafka after tests
      - name: Stop Kafka
        continue-on-error: true
        if: always()
        run: docker compose -f ./sample-app/backend/src/events/kafka-cluster.yml down

      - name: Copy trace files to blob-report
        run: |
          mkdir -p blob-report/trace
          cp -r test-results/**/*.zip blob-report/trace || true

      - name: Upload shared blob report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: blob-report-${{ matrix.shardIndex }}
          path: blob-report
          retention-days: 3

  merge-reports:
    needs: e2e-test
    # even if the previous jobs in the needs: list failed, still run this job
    if: always() && needs.burn-in.outputs.runE2E == 'true'
    runs-on: kubernetes-default
    steps:
      - name: Download shard reports
        uses: actions/download-artifact@v4
        with:
          path: all-blob-reports
          pattern: blob-report-*
          merge-multiple: true

      - name: Merge Playwright reports
        run: |
          mkdir -p playwright-report/trace
          cp -r all-blob-reports/*/trace/* playwright-report/trace || true
          npx playwright merge-reports --reporter=html all-blob-reports

      - name: Upload merged report
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
          retention-days: 3
